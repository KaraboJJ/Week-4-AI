# AI in Software Development: Coursework Project

## Overview

This project explores the application of Artificial Intelligence in software development through a comprehensive three-part structure: theoretical analysis, practical implementation, and ethical reflection. Topics include AI-assisted coding, bug detection, test automation, predictive analytics, and fairness in AI.

---

## Part 1: Theoretical Analysis 

### 1.1 Short Answer Questions

- **Q1: AI-Driven Code Generation Tools**
  - Tools like GitHub Copilot assist in real-time code suggestions, reducing development time by automating boilerplate code and leveraging vast open-source knowledge.
  - Limitations include contextual misunderstandings, potential for insecure code, and lack of explainability.

- **Q2: Supervised vs. Unsupervised Learning in Bug Detection**
  - Supervised learning uses labeled data to predict bug types or severity.
  - Unsupervised learning detects anomalies in unlabeled code or logs.
  - Both methods are complementary in modern bug detection pipelines.

- **Q3: Bias Mitigation in Personalization**
  - AI personalization can marginalize underrepresented users if training data is biased.
  - Mitigation ensures inclusivity and fairness, improving user satisfaction and system credibility.

### 1.2 Case Study: AIOps in DevOps

- **Efficiency Improvements**
  - Automates anomaly detection and root-cause analysis in CI/CD.
  - Minimizes manual intervention, reducing deployment time and failure rates.

- **Examples**
  1. Predictive server scaling during deployments.
  2. Automated rollback on error spike detection.

---

## Part 2: Practical Implementation 

### Task 1: AI-Powered Code Completion

- **Objective**: Sort a list of dictionaries in Python by a given key.
- **Tools Used**: GitHub Copilot
- **Comparison**: Copilot's code is concise and efficient. Manual code offers more control but takes longer.
- **Deliverables**:
  - AI-generated and manually written Python code snippets.
  - 200-word performance and efficiency analysis.

### Task 2: Automated Testing with AI

- **Objective**: Automate login page testing using AI-enabled tools.
- **Tools Used**: Selenium IDE + AI plugins / Testim.io
- **Tasks**:
  - Validate login with correct and incorrect credentials.
  - Record success/failure outcomes.
- **Deliverables**:
  - AI-generated test script.
  - Screenshot of test results.
  - 150-word summary on AI-enhanced test coverage.

### Task 3: Predictive Analytics for Resource Allocation

- **Dataset**: Kaggle Breast Cancer Dataset
- **Goal**: Predict issue priority (High/Medium/Low)
- **Methods**:
  - Data preprocessing and cleaning.
  - Model training using Random Forest.
  - Evaluation via accuracy and F1-score.
- **Deliverables**:
  - Jupyter Notebook
  - Performance summary (accuracy and F1-score)

---

## Part 3: Ethical Reflection 

- **Topic**: Bias and Fairness in Predictive Models
- **Issues Identified**:
  - Dataset may be biased due to underrepresented groups or teams.
  - Deployment could lead to unfair prioritization or resource allocation.
- **Mitigation Tools**:
  - IBM AI Fairness 360 to evaluate and reduce bias.
  - Use of demographic parity, equal opportunity, and fairness metrics to ensure equity.

---

## Files Included

- `README.md` – Project summary and documentation
- `task1_code_completion.py` – AI-generated and manual sorting code
- `task2_login_test.side` – Selenium IDE test script
- `task2_results.png` – Screenshot of test results
- `task2_summary.txt` – Testing analysis summary
- `task3_breast_cancer_prediction.ipynb` – Jupyter notebook for predictive analytics
- `task3_metrics.pdf` – Model performance report
- `ethics_reflection.txt` – Fairness and bias discussion

---

## Tools & Technologies

- **Languages**: Python, HTML (for testing)
- **AI Tools**: GitHub Copilot, IBM AI Fairness 360
- **Testing Frameworks**: Selenium IDE, Testim.io
- **ML Libraries**: scikit-learn, pandas, matplotlib

---

## Author

Karabo Masipa  

